{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8883021b",
   "metadata": {},
   "source": [
    "<a id=\"TableOfContents\"></a>\n",
    "# TABLE OF CONTENTS:\n",
    "<li><a href='#imports'>Imports</a></li>\n",
    "<li><a href=\"#Q1\">Question 1</a></li>\n",
    "<li><a href='#Q2'>Question 2</a></li>\n",
    "<li><a href='#Q3'>Question 3</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b5a37",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "# IMPORTS:\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f5af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization and tables\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Datasets\n",
    "from pydataset import data\n",
    "\n",
    "# sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# .py files\n",
    "import wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09c9f16",
   "metadata": {},
   "source": [
    "<a id='Q1'></a>\n",
    "# Question 1:\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a65bea",
   "metadata": {},
   "source": [
    "### 1. Select a dataset with a continuous target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6db17a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape:(1069116, 12)\n",
      "validate.shape:(458193, 12)\n",
      "test.shape:(381828, 12)\n"
     ]
    }
   ],
   "source": [
    "# Obtain zillow df, split, then reduce sample size\n",
    "train, validate, test = wrangle.wrangle_zillow()\n",
    "train_sample, validate_sample, test_sample = wrangle.sample_dataframe(train, validate, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b171f7",
   "metadata": {},
   "source": [
    "<a id='Q2'></a>\n",
    "# Question 2:\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a9c42",
   "metadata": {},
   "source": [
    "### 2. Be sure your data is prepared (no missing values, numeric datatypes) and split into samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ef474b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 12), (428, 12), (357, 12))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify smaller sample size\n",
    "train_sample.shape, validate_sample.shape, test_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028bdb0",
   "metadata": {},
   "source": [
    "<a id='Q3'></a>\n",
    "# Question 3:\n",
    "<li><a href='#TableOfContents'>Table of Contents</a></li>\n",
    "<li><a href='#initial'>Initial</a></li>\n",
    "<li><a href='#baseline'>Baseline</a></li>\n",
    "<li><a href='#ols'>LinearRegression(OLS)</a></li>\n",
    "<li><a href='#ll'>LassoLars</a></li>\n",
    "<li><a href='#tdr'>TweedieRegressor</a></li>\n",
    "<li><a href='#pnr'>Polynomial Regression</a></li>\n",
    "<li><a href='#best'>Best Model Testing</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cdd3c7",
   "metadata": {},
   "source": [
    "### 3. Work through all of the steps outlined in the lesson, from setting the baseline to selected a model and evaluating the final model on your test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f88ecd",
   "metadata": {},
   "source": [
    "<a id='initial'></a>\n",
    "##### Initial\n",
    "<li><a href='#Q3'>Question 3 Top</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c466ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'bedroomcnt',\n",
    "    'bathroomcnt',\n",
    "    'sqrft'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe652da4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scale() missing 1 required positional argument: 'scaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6x/kctcvd8x6l18t57t92kmqy6w0000gn/T/ipykernel_41739/1196300647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Scale dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_sample_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_sample_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: scale() missing 1 required positional argument: 'scaler'"
     ]
    }
   ],
   "source": [
    "# Scale dataframes\n",
    "train_sample_scaled, validate_sample_scaled, test_sample_scaled = wrangle.scale(train_sample, validate_sample, test_sample, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define x_col, y_col for train, validate, test\n",
    "x_train = train_sample_scaled.drop(columns=['assessedvalue', 'taxamount'])\n",
    "y_train = pd.DataFrame(train_sample_scaled.assessedvalue)\n",
    "x_validate = validate_sample_scaled.drop(columns=['assessedvalue', 'taxamount'])\n",
    "y_validate = pd.DataFrame(validate_sample_scaled.assessedvalue)\n",
    "x_test = test_sample_scaled.drop(columns=['assessedvalue', 'taxamount'])\n",
    "y_test = pd.DataFrame(test_sample_scaled.assessedvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0e86e",
   "metadata": {},
   "source": [
    "<a id='baseline'></a>\n",
    "##### Baseline\n",
    "<li><a href='#Q3'>Question 3 Top</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd623af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mean and median baseline values\n",
    "baseline_mean = y_train.assessedvalue.mean()\n",
    "y_train['baseline_mean'] = baseline_mean\n",
    "y_validate['baseline_mean'] = baseline_mean\n",
    "baseline_median = y_train.assessedvalue.median()\n",
    "y_train['baseline_median'] = baseline_median\n",
    "y_validate['baseline_median'] = baseline_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e802c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare mean/median RMSE scores\n",
    "rmse_train_mean = mean_squared_error(y_train.assessedvalue,\n",
    "                                    y_train.baseline_mean) ** .5\n",
    "rmse_validate_mean = mean_squared_error(y_validate.assessedvalue,\n",
    "                                    y_validate.baseline_mean) ** .5\n",
    "rmse_train_median = mean_squared_error(y_train.assessedvalue,\n",
    "                                    y_train.baseline_median) ** .5\n",
    "rmse_validate_median = mean_squared_error(y_validate.assessedvalue,\n",
    "                                    y_validate.baseline_median) ** .5\n",
    "\n",
    "print('\\033[35m ========== MEAN RMSE SCORES ==========\\033[0m')\n",
    "print(f'\\033[32mTrain:\\033[0m {rmse_train_mean}\\n\\033[32mValidate:\\033[0m {rmse_validate_mean}\\n\\033[32mDifference:\\033[0m {rmse_validate_mean - rmse_train_mean}')\n",
    "print('\\n\\n\\033[35m ========== MEDIAN RMSE SCORES ==========\\033[0m')\n",
    "print(f'\\033[32mTrain:\\033[0m {rmse_train_median}\\n\\033[32mValidate:\\033[0m {rmse_validate_median}\\n\\033[32mDifference:\\033[0m {rmse_validate_median - rmse_train_median}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b929d65",
   "metadata": {},
   "source": [
    "### Mean is the better baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ab29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of model scores\n",
    "models_dict = {\n",
    "    'model_name' : ['baseline_mean'],\n",
    "    'model_type' : ['baseline'],\n",
    "    'train_rmse' : [round(rmse_train_mean, 2)],\n",
    "    'validate_rmse' : [round(rmse_validate_mean, 2)],\n",
    "    'difference' : [round(rmse_validate_mean - rmse_train_mean, 2)],\n",
    "    'validate_r2' : [round(explained_variance_score(y_validate.assessedvalue,\n",
    "                                             y_validate.baseline_mean), 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e9790",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Verify compatability with pandas\n",
    "pd.DataFrame([models_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655dcd9",
   "metadata": {},
   "source": [
    "<a id='ols'></a>\n",
    "##### LinearRegression(OLS)\n",
    "<li><a href='#Q3'>Question 3 Top</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validate predictions with lr modeling\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train.assessedvalue)\n",
    "y_train['lr_pred'] = lr.predict(x_train)\n",
    "y_validate['lr_pred'] = lr.predict(x_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d4850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RMSE vals for train/validate\n",
    "# Append to 'models_dict'\n",
    "lr_rmse_train = mean_squared_error(y_train.assessedvalue,\n",
    "                                   y_train.lr_pred) ** .5\n",
    "lr_rmse_validate = mean_squared_error(y_validate.assessedvalue,\n",
    "                                      y_validate.lr_pred) ** .5\n",
    "models_dict['model_name'].append('lr')\n",
    "models_dict['model_type'].append('LinearRegression')\n",
    "models_dict['train_rmse'].append(round(lr_rmse_train, 2))\n",
    "models_dict['validate_rmse'].append(round(lr_rmse_validate, 2))\n",
    "models_dict['difference'].append(round(lr_rmse_validate - lr_rmse_train, 2))\n",
    "models_dict['validate_r2'].append(round(explained_variance_score(y_validate.assessedvalue,\n",
    "                                                                 y_validate.lr_pred), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf06f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(models_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f91fd17",
   "metadata": {},
   "source": [
    "<a id='ll'></a>\n",
    "##### LassoLars\n",
    "<li><a href='#Q3'>Question 3 Top</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validate predictions with LassoLars\n",
    "ll1 = LassoLars(alpha=1)\n",
    "ll1.fit(x_train, y_train.assessedvalue)\n",
    "y_train['ll_pred_1.0'] = ll1.predict(x_train)\n",
    "y_validate['ll_pred_1.0'] = ll1.predict(x_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d93d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RMSE values and append to 'models_dict'\n",
    "ll_rmse_train = mean_squared_error(y_train.assessedvalue,\n",
    "                                   y_train['ll_pred_1.0']) ** .5\n",
    "ll_rmse_validate = mean_squared_error(y_validate.assessedvalue,\n",
    "                                      y_validate['ll_pred_1.0']) ** .5\n",
    "models_dict['model_name'].append('ll_1.0')\n",
    "models_dict['model_type'].append('LassoLars')\n",
    "models_dict['train_rmse'].append(round(ll_rmse_train, 2))\n",
    "models_dict['validate_rmse'].append(round(ll_rmse_validate, 2))\n",
    "models_dict['difference'].append(round(ll_rmse_validate - ll_rmse_train, 2))\n",
    "models_dict['validate_r2'].append(round(explained_variance_score(y_validate.assessedvalue,\n",
    "                                                                 y_validate['ll_pred_1.0']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ll pred with alpha = 0.1\n",
    "ll01 = LassoLars(alpha=0.1)\n",
    "ll01.fit(x_train, y_train.assessedvalue)\n",
    "y_train['ll_pred_0.1'] = ll01.predict(x_train)\n",
    "y_validate['ll_pred_0.1'] = ll01.predict(x_validate)\n",
    "ll_rmse_train01 = mean_squared_error(y_train.assessedvalue,\n",
    "                                   y_train['ll_pred_0.1']) ** .5\n",
    "ll_rmse_validate01 = mean_squared_error(y_validate.assessedvalue,\n",
    "                                      y_validate['ll_pred_0.1']) ** .5\n",
    "models_dict['model_name'].append('ll_0.1')\n",
    "models_dict['model_type'].append('LassoLars')\n",
    "models_dict['train_rmse'].append(round(ll_rmse_train01, 2))\n",
    "models_dict['validate_rmse'].append(round(ll_rmse_validate01, 2))\n",
    "models_dict['difference'].append(round(ll_rmse_validate01 - ll_rmse_train01, 2))\n",
    "models_dict['validate_r2'].append(round(explained_variance_score(y_validate.assessedvalue,\n",
    "                                                                 y_validate['ll_pred_0.1']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a16b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(models_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b8023",
   "metadata": {},
   "source": [
    "<a id='tdr'></a>\n",
    "##### TweedieRegressor\n",
    "<li><a href='#Q3'>Question 3 Top</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22659b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validate predictions with TweedieRegressor\n",
    "tdr0 = TweedieRegressor(power=0, alpha=1)\n",
    "tdr0.fit(x_train, y_train.assessedvalue)\n",
    "y_train['tdr_pow0_a1'] = tdr0.predict(x_train)\n",
    "y_validate['tdr_pow0_a1'] = tdr0.predict(x_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RMSE values and append to 'models_dict'\n",
    "tdr_rmse_train0_1 = mean_squared_error(y_train.assessedvalue,\n",
    "                                   y_train['tdr_pow0_a1']) ** .5\n",
    "tdr_rmse_validate0_1 = mean_squared_error(y_validate.assessedvalue,\n",
    "                                      y_validate['tdr_pow0_a1']) ** .5\n",
    "models_dict['model_name'].append('tdr_pow0_a1')\n",
    "models_dict['model_type'].append('TweedieRegressor')\n",
    "models_dict['train_rmse'].append(round(tdr_rmse_train0_1, 2))\n",
    "models_dict['validate_rmse'].append(round(tdr_rmse_validate0_1, 2))\n",
    "models_dict['difference'].append(round(tdr_rmse_validate0_1 - tdr_rmse_train0_1, 2))\n",
    "models_dict['validate_r2'].append(round(explained_variance_score(y_validate.assessedvalue,\n",
    "                                                                 y_validate['tdr_pow0_a1']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdr power = 1\n",
    "tdr1 = TweedieRegressor(power=1, alpha=1)\n",
    "tdr1.fit(x_train, y_train.assessedvalue)\n",
    "y_train['tdr_pow1_a1'] = tdr1.predict(x_train)\n",
    "y_validate['tdr_pow1_a1'] = tdr1.predict(x_validate)\n",
    "tdr_rmse_train1_1 = mean_squared_error(y_train.assessedvalue,\n",
    "                                   y_train['tdr_pow1_a1']) ** .5\n",
    "tdr_rmse_validate1_1 = mean_squared_error(y_validate.assessedvalue,\n",
    "                                      y_validate['tdr_pow1_a1']) ** .5\n",
    "models_dict['model_name'].append('tdr_pow1_a1')\n",
    "models_dict['model_type'].append('TweedieRegressor')\n",
    "models_dict['train_rmse'].append(round(tdr_rmse_train1_1, 2))\n",
    "models_dict['validate_rmse'].append(round(tdr_rmse_validate1_1, 2))\n",
    "models_dict['difference'].append(round(tdr_rmse_validate1_1 - tdr_rmse_train1_1, 2))\n",
    "models_dict['validate_r2'].append(round(explained_variance_score(y_validate.assessedvalue,\n",
    "                                                                 y_validate['tdr_pow1_a1']), 2))\n",
    "\n",
    "# tdr power = 2\n",
    "tdr2 = TweedieRegressor(power=2, alpha=1)\n",
    "tdr2.fit(x_train, y_train.assessedvalue)\n",
    "y_train['tdr_pow2_a1'] = tdr2.predict(x_train)\n",
    "y_validate['tdr_pow2_a1'] = tdr2.predict(x_validate)\n",
    "tdr_rmse_train2_1 = mean_squared_error(y_train.assessedvalue,\n",
    "                                   y_train['tdr_pow2_a1']) ** .5\n",
    "tdr_rmse_validate2_1 = mean_squared_error(y_validate.assessedvalue,\n",
    "                                      y_validate['tdr_pow2_a1']) ** .5\n",
    "models_dict['model_name'].append('tdr_pow2_a1')\n",
    "models_dict['model_type'].append('TweedieRegressor')\n",
    "models_dict['train_rmse'].append(round(tdr_rmse_train2_1, 2))\n",
    "models_dict['validate_rmse'].append(round(tdr_rmse_validate2_1, 2))\n",
    "models_dict['difference'].append(round(tdr_rmse_validate2_1 - tdr_rmse_train2_1, 2))\n",
    "models_dict['validate_r2'].append(round(explained_variance_score(y_validate.assessedvalue,\n",
    "                                                                 y_validate['tdr_pow2_a1']), 2))\n",
    "\n",
    "# tdr power = 3\n",
    "tdr3 = TweedieRegressor(power=1, alpha=1)\n",
    "tdr3.fit(x_train, y_train.assessedvalue)\n",
    "y_train['tdr_pow3_a1'] = tdr3.predict(x_train)\n",
    "y_validate['tdr_pow3_a1'] = tdr3.predict(x_validate)\n",
    "tdr_rmse_train3_1 = mean_squared_error(y_train.assessedvalue,\n",
    "                                   y_train['tdr_pow3_a1']) ** .5\n",
    "tdr_rmse_validate3_1 = mean_squared_error(y_validate.assessedvalue,\n",
    "                                      y_validate['tdr_pow3_a1']) ** .5\n",
    "models_dict['model_name'].append('tdr_pow3_a1')\n",
    "models_dict['model_type'].append('TweedieRegressor')\n",
    "models_dict['train_rmse'].append(round(tdr_rmse_train3_1, 2))\n",
    "models_dict['validate_rmse'].append(round(tdr_rmse_validate3_1, 2))\n",
    "models_dict['difference'].append(round(tdr_rmse_validate3_1 - tdr_rmse_train3_1, 2))\n",
    "models_dict['validate_r2'].append(round(explained_variance_score(y_validate.assessedvalue,\n",
    "                                                                 y_validate['tdr_pow3_a1']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6856606",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(models_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684997e9",
   "metadata": {},
   "source": [
    "<a id='pnr'></a>\n",
    "##### Polynomial Regression\n",
    "<li><a href='#Q3'>Question 3 Top</a></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d759a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "x_validate_poly = poly.transform(x_validate)\n",
    "x_test_poly = poly.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f3a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val preds using 'polynomial regression'\n",
    "pnr = LinearRegression()\n",
    "pnr.fit(x_train_poly, y_train.assessedvalue)\n",
    "y_train['poly'] = pnr.predict(x_train_poly)\n",
    "y_validate['poly'] = pnr.predict(x_validate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc2c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get RMSE values and append to 'models_dict'\n",
    "pnr_rmse_train = mean_squared_error(y_train.assessedvalue,\n",
    "                                   y_train['poly']) ** .5\n",
    "pnr_rmse_validate = mean_squared_error(y_validate.assessedvalue,\n",
    "                                      y_validate['poly']) ** .5\n",
    "models_dict['model_name'].append('poly')\n",
    "models_dict['model_type'].append('Polynomial Regression')\n",
    "models_dict['train_rmse'].append(round(pnr_rmse_train, 2))\n",
    "models_dict['validate_rmse'].append(round(pnr_rmse_validate, 2))\n",
    "models_dict['difference'].append(round(pnr_rmse_validate - pnr_rmse_train, 2))\n",
    "models_dict['validate_r2'].append(round(explained_variance_score(y_validate.assessedvalue,\n",
    "                                                                 y_validate['poly']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962addd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(models_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de6a989",
   "metadata": {},
   "source": [
    "<a id='best'></a>\n",
    "##### Best Model Testing\n",
    "<li><a href='#Q3'>Question 3 Top</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785802f6",
   "metadata": {},
   "source": [
    "'ll_0.1' is best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test\n",
    "y_test['ll_0.1'] = ll01.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeecd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to models_dict\n",
    "testll01_rmse_test = mean_squared_error(y_test.assessedvalue,\n",
    "                                   y_test['ll_0.1']) ** .5\n",
    "models_dict['model_name'].append('TESTING_ll01')\n",
    "models_dict['model_type'].append('LassoLars')\n",
    "models_dict['train_rmse'].append(0)\n",
    "models_dict['validate_rmse'].append(round(testll01_rmse_test, 2))\n",
    "models_dict['difference'].append(0)\n",
    "models_dict['validate_r2'].append(round(explained_variance_score(y_test.assessedvalue,\n",
    "                                                                 y_test['ll_0.1']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc23dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ecc78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
